services:
  ai-router:
    build: .
    image: ai-router:local
    ports:
      - "8082:8082"
    env_file:
      - ./config/.env.local
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    healthcheck:
      test: [ "CMD", "curl", "-fsS", "http://localhost:8082/healthz" ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
